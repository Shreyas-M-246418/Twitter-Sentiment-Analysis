{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "!kaggle datasets download -d kazanova/sentiment140\n",
    "\n",
    "from zipfile import ZipFile\n",
    "\n",
    "dataset='/content/sentiment140.zip'\n",
    "\n",
    "with ZipFile(dataset,'r') as zip:\n",
    "  zip.extractall()\n",
    "  print(\"The Dataset is extracted\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "print(stopwords.words('english'))\n",
    "\n",
    "df=pd.read_csv('/content/training.1600000.processed.noemoticon.csv',encoding='ISO-8859-1')\n",
    "\n",
    "df.shape\n",
    "\n",
    "df.head()\n",
    "\n",
    "column_names=['target','id','date','flag','user','text']\n",
    "df=pd.read_csv('/content/training.1600000.processed.noemoticon.csv',names=column_names,encoding='ISO-8859-1')\n",
    "\n",
    "df.head()\n",
    "\n",
    "df.isnull().sum()\n",
    "\n",
    "df['target'].value_counts()\n",
    "\n",
    "df.replace({'target':{4:1}}, inplace=True)\n",
    "\n",
    "df['target'].value_counts()\n",
    "\n",
    "port_stem=PorterStemmer()\n",
    "\n",
    "def stemming(content):\n",
    "\n",
    "  stemmed_content=re.sub('[^a-zA-Z]',' ',content)\n",
    "  stemmed_content=stemmed_content.lower()\n",
    "  stemmed_content=stemmed_content.split()\n",
    "  stemmed_content=[port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')]\n",
    "  stemmed_content=' '.join(stemmed_content)\n",
    "\n",
    "  return stemmed_content\n",
    "\n",
    "df['stemmed_content']=df['text'].apply(stemming)\n",
    "\n",
    "df.head()\n",
    "\n",
    "x=df['stemmed_content'].values\n",
    "y=df['target'].values\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,stratify=y,random_state=2)\n",
    "\n",
    "vectorizer=TfidfVectorizer()\n",
    "x_train=vectorizer.fit_transform(x_train)\n",
    "x_test=vectorizer.transform(x_test)\n",
    "\n",
    "lr=LogisticRegression(max_iter=1000)\n",
    "\n",
    "lr.fit(x_train,y_train)\n",
    "\n",
    "y_pred=lr.predict(x_test)\n",
    "\n",
    "acc=accuracy_score(y_test,y_pred)\n",
    "print(acc)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "filename='trained_model.sav'\n",
    "pickle.dump(lr,open(filename,'wb'))\n",
    "\n",
    "with open('vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf_vectorizer, f)\n",
    "\n",
    "loaded_model=pickle.load(open('/content/trained_model.sav','rb'))\n",
    "\n",
    "x_new=x[6000]\n",
    "print(y[6000])\n",
    "pred=loaded_model.predict(x_new)\n",
    "print(pred)\n",
    "\n",
    "if(pred[0]==0):\n",
    "  print(\"Negative\")\n",
    "else:\n",
    "  print(\"Positive\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
